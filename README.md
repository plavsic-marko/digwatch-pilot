# digwatch-pilot â€” README (V2)

Minimalni vodiÄ za pokretanje **RAG pipeline-a za dig.watch Updates** na lokalnoj maÅ¡ini (Windows, VS Code/CMD).

---

## 0) Pregled

Tok rada (V2):

1. **Crawler (taxonomy + updates)** â†’ preuzmi kategorije/tagove i sve `updates` zapise sa dig.watch.
2. **Chunker** â†’ oÄisti HTML i podeli na pasuse (dodaje meta: `quarter`, `effective_date`, `tags`, `categories`).
3. **Schema** â†’ kreiraj klase u Weaviate (`DigwatchUpdate`, `DigwatchParagraph`).
4. **Ingest** â†’ upiÅ¡i dokumente i pasuse u Weaviate sa relacijama (`updateRef`).
5. **Query** â†’ sanity check (BM25 ili hibrid).
6. **Eval (opciono)** â†’ lokalno testiranje na JSONL upitima.

---

## 1) Prerekviziti

- Python 3.10+
- Virtuelno okruÅ¾enje (`venv/`)
- Docker sa Weaviate + `text2vec-transformers` modelom (npr. `all-MiniLM-L6-v2`)

Pokreni Weaviate:

```bash
docker run -d --name weaviate \
  -p 8080:8080 -e QUERY_DEFAULTS_LIMIT=20 \
  -e AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true \
  -e PERSISTENCE_DATA_PATH="/var/lib/weaviate" \
  semitechnologies/weaviate:1.25.8
```

---

## 2) Brzi start â€” komande (redom)

### (a) Fetch taxonomy

```bash
python crawler/fetch_taxonomies.py
```

Output:

- `data/raw/categories.json`
- `data/raw/taxonomy_map.json`

---

### (b) Collect updates (full crawl)

```bash
python crawler/collect_updates_full.py
```

Output:

- `data/raw/updates_all.json`
- `data/raw/updates_state.json`

Ako dobijeÅ¡ `400 Bad Request` na zadnjoj stranici â†’ znaÄi da je kraj paginacije.

---

### (c) Chunk updates

```bash
python chunker/chunk_updates_v1.py
```

Output:

- `data/processed/updates_paragraphs.jsonl`

Dodaje polja: `quarter`, `effective_date`, `tag_names`, `category_names`.

---

### (d) Create schema (Weaviate)

```bash
python scripts/create_schema_digwatch.py
```

Kreira:

- `DigwatchUpdate` (document-level meta)
- `DigwatchParagraph` (pasus-level) sa `updateRef` relacijom

---

### (e) Ingest hierarchy

```bash
python scripts/ingest_hierarchy_digwatch.py
```

Output primer:

```
 Ingest done. Paragraphs: 75501, Updates: 24091
```

---

### (f) Query sanity check

```bash
python scripts/query_weaviate.py "AI Act" --alpha 0.35 --k 5
```

Output: prikazuje naslove, linkove i iseÄke.

---

### (g) (Opcionalno) Lokalni offline check

```bash
python search_jsonl.py "AI Act"
```

Radi pretragu direktno po `updates_paragraphs.jsonl`.

---

## 3) Struktura projekta

```
crawler/
  â”œâ”€ fetch_taxonomies.py
  â””â”€ collect_updates_full.py

chunker/
  â””â”€ chunk_updates_v1.py

scripts/
  â”œâ”€ create_schema_digwatch.py
  â”œâ”€ ingest_hierarchy_digwatch.py
  â”œâ”€ query_weaviate.py
  â”œâ”€ query_any.py
  â””â”€ debug_query.py

eval/
  â”œâ”€ test_queries.jsonl
  â””â”€ evaluate_local.py

data/
  â”œâ”€ raw/
  â”‚   â”œâ”€ taxonomy_map.json
  â”‚   â”œâ”€ updates_all.json
  â”‚   â””â”€ updates_state.json
  â””â”€ processed/
      â””â”€ updates_paragraphs.jsonl

api.py              # FastAPI servis (/healthz, /retrieve_digwatch)
requirements.txt    # Python zavisnosti
README.md           # ovaj fajl
```

---

ğŸ‘‰ TL;DR koraci:  
`fetch_taxonomies â†’ collect_updates_full â†’ chunk_updates_v1 â†’ create_schema_digwatch â†’ ingest_hierarchy_digwatch â†’ query_weaviate`
